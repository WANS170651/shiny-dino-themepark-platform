install.packages("languageserver")
installed.packages("httpgd")
R.home()
where R
where Rscript
install.packages('IRkernel')
1+1
install.packages("languageserver")
remove.packages("languageserver")
install.packages("bibliometrix", dependencies=TRUE)
library(bibliometrix)
biblioshiny()
install.packages("readxl")
install.packages("networkD3")
library(readxl)
library(dplyr)
library(networkD3)
library(tidyverse)
file_path <- ""C:\Users\Mark\Downloads\Customer churn_Assignment 2.xlsx"
file_path <- "C:\Users\Mark\Downloads\Customer churn_Assignment 2.xlsx"
file_path <- "C:/Users/Mark/Downloads/Customer churn_Assignment 2.xlsx"
df <- readxl::read_excel(file_path)
# 创建节点（Nodes）
nodes <- data.frame(name = unique(c(df$gender, df$Contract, df$PaymentMethod, df$ChurnYesNo)))
# 创建链接（Links）
links <- df %>%
group_by(gender, Contract, PaymentMethod, ChurnYesNo) %>%
summarise(value = n()) %>%
ungroup() %>%
pivot_longer(cols = c(gender, Contract, PaymentMethod, ChurnYesNo), names_to = "source_target", values_to = "category") %>%
group_by(source_target, category) %>%
summarise(value = sum(value)) %>%
ungroup()
# 匹配节点索引
links <- links %>%
mutate(source = match(category, nodes$name) - 1) %>%
arrange(source) %>%
mutate(target = lead(source)) %>%
filter(!is.na(target)) %>%
select(source, target, value)
# 绘制桑基图
sankey <- sankeyNetwork(Links = links, Nodes = nodes,
Source = "source", Target = "target",
Value = "value", NodeID = "name",
fontSize = 12, nodeWidth = 30)
# 显示桑基图
sankey
# 创建节点（Nodes）
nodes <- data.frame(name = unique(c(df$gender, df$Contract, df$PaymentMethod, df$ChurnYesNo)))
# 创建链接（Links）
links <- df %>%
select(gender, Contract, PaymentMethod, ChurnYesNo) %>%
pivot_longer(cols = everything(), names_to = "source_target", values_to = "category") %>%
group_by(source_target, category) %>%
summarise(value = n(), .groups = 'drop') %>%
ungroup()
# 生成索引匹配
links <- links %>%
mutate(source = match(category, nodes$name) - 1) %>%
arrange(source) %>%
mutate(target = lead(source)) %>%
filter(!is.na(target)) %>%
select(source, target, value)
# 绘制桑基图
sankey <- sankeyNetwork(Links = links, Nodes = nodes,
Source = "source", Target = "target",
Value = "value", NodeID = "name",
fontSize = 14, nodeWidth = 40, units = "Customers")
# 显示桑基图
sankey
install.packages('tm')
get_sentiments('nrc')
nrc = get_sentiments('nrc')
library(textdata)
nrc = get_sentiments('nrc')
library(tidytext)
library(dplyr)
nrc <- get_sentiments("nrc")
afinn = get_sentiments('afinn')
version
R.version.string
install.packages('lm.beta')
install.packages('gridExtra')
install.packages('factoextra')
install.packages('psych')
save_path <- "D:/APAN5205_Notes/r_packages.csv"  # 根据需要修改路径
installed_packages <- unique(data.frame(installed.packages())[,c("Package", "Version")])
write.csv(installed_packages, file = save_path, row.names = FALSE)
install.packages('flexclust')
install.packages('FactoMineR')
install.packages('janitor')
install.packages('RColorBrewer')
install.packages('recommenderlab')
install.packages('ggthemes')
install.packages('gridExtra')
install.packages('quantmod')
install.packages('zoo')
install.packages('forecast')
install.packages('fpp')
install.packages('fpp2')
install.packages('tseries')
# 查看当前工作目录
getwd()
# 设置指定工作目录（替换为你想保存的路径）
setwd("C:\Users\Mark\Desktop\qwe)
# 查看当前工作目录
getwd()
# 设置指定工作目录（替换为你想保存的路径）
setwd("C:/Users/Mark/Desktop/qwe)
# 然后执行导出命令
installed_packages <- data.frame(installed.packages())
write.csv(installed_packages[,c("Package", "Version")], "r_packages.csv")
getwd()
setwd("C:/Users/Mark/Desktop/qwe)
installed_packages <- data.frame(installed.packages())
write.csv(installed_packages[,c("Package", "Version")], "r_packages.csv")
# 导出已安装的包列表
packages <- installed.packages()
write.csv(packages[,c("Package","Version")], "r_packages.csv")
getwd()
setwd("C:/Users/Mark/Desktop/qwe)
packages <- installed.packages()
write.csv(packages[,c("Package","Version")], "r_packages.csv")
# 自定义导出路径，例如 D 盘、桌面等
save_path <- "C:/Users/Mark/Desktop/qwe"  # 改为你想保存的位置
# 导出当前用户安装的包列表
installed <- installed.packages()[, "Package"]
writeLines(installed, save_path)
# 设置保存路径，必须是一个具体的 .txt 文件
save_path <- "C:/Users/Mark/Desktop/installed_packages.txt"
# 创建上级目录（如果不存在）
dir.create(dirname(save_path), recursive = TRUE, showWarnings = FALSE)
# 导出当前已安装包名
installed <- installed.packages()[, "Package"]
writeLines(installed, save_path)
cat("包列表已成功导出至：", save_path)
# —— 第一步：设置导出文件路径 ——
# 改成你想保存的具体路径，并确保所在文件夹可写
export_path <- "C:/Users/Mark/Desktop/R_pkg_versions.csv"
# —— 第二步：导出包名和版本号 ——
pkg_info <- installed.packages()[, c("Package", "Version")]
# 保存为 CSV，便于后续读取
write.csv(pkg_info, file = export_path, row.names = FALSE)
cat("已导出", nrow(pkg_info), "个包的信息至：", export_path, "\n")
install.packages(c("leaflet", "RPostgres", "shiny", "shinyalert",
"shinythemes", "shinyWidgets", "tidyverse"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(randomForest)
library(caret)
library(pROC)
library(tidyverse)
library(randomForest)
library(caret)
library(pROC)
df <- read.csv("DOHMH_HIV_AIDS_Cleaned.csv")
unlink("C:/Users/Mark/Desktop/123123_cache", recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(randomForest)
library(caret)
library(pROC)
df <- read.csv(D:\\APAN5205_Notes\\Project\\DOHMH_HIV_AIDS_Cleaned.csv)
df <- read.csv(D:/APAN5205_Notes/Project/DOHMH_HIV_AIDS_Cleaned.csv)
df <- read.csv("D:/APAN5205_Notes/Project/DOHMH_HIV_AIDS_Cleaned.csv")
summary(df$x_linked_to_care_within_3_months)
df <- df %>%
mutate(linked_class = ifelse(x_linked_to_care_within_3_months >= 0.85, "High", "Low")) %>%
mutate(linked_class = as.factor(linked_class))
df_model <- df %>%
select(linked_class, year, borough, uhf, gender, age, race, hiv_diagnoses, aids_diagnoses) %>%
drop_na() %>%
mutate(across(c(year, borough, uhf, gender, age, race), as.factor))
set.seed(42)
split_idx <- createDataPartition(df_model$linked_class, p = 0.8, list = FALSE)
train <- df_model[split_idx, ]
test  <- df_model[-split_idx, ]
set.seed(42)
rf_model <- randomForest(linked_class ~ ., data = train, ntree = 500, importance = TRUE)
# predict
pred <- predict(rf_model, newdata = test)
# confusion matrix
confusionMatrix(pred, test$linked_class)
# calculate ROC and AUC
prob_pred <- predict(rf_model, newdata = test, type = "prob")
roc_obj <- roc(response = test$linked_class,
predictor = prob_pred[,"High"],
levels = rev(levels(test$linked_class)))
par(bg = "white")
plot(roc_obj, col = "#2C3E50", lwd = 3, main = "ROC Curve - Random Forest")
abline(a = 0, b = 1, lty = 2, col = "gray")
auc(roc_obj)
# calculate ROC and AUC
prob_pred <- predict(rf_model, newdata = test, type = "prob")
roc_obj <- roc(response = test$linked_class,
predictor = prob_pred[,"High"],
levels = rev(levels(test$linked_class)))
plot(roc_obj, col = "#2C3E50", lwd = 3, main = "ROC Curve - Random Forest")
abline(a = 0, b = 1, lty = 2, col = "gray")
auc(roc_obj)
# variable importance
importance(rf_model)
# plot variable importance
par(bg = "white")
varImpPlot(rf_model,
type = 1,
main = "Variable Importance - Random Forest",
col = "#2C3E50")
# calculate the proportion of high linkage rates by UHF
df_model %>%
group_by(uhf) %>%
summarise(
total = n(),
high_count = sum(linked_class == "High"),
high_rate = high_count / total
) %>%
arrange(desc(high_rate))
# visualize the proportion of high linkage rates by UHF
df_model %>%
group_by(uhf) %>%
summarise(high_rate = mean(linked_class == "High")) %>%
ggplot(aes(x = reorder(uhf, high_rate), y = high_rate)) +
geom_col(fill = "#2C3E50") +
coord_flip() +
labs(title = "Proportion of 'High' Linked Care by UHF Region",
x = "UHF Region", y = "Proportion High") +
theme_minimal()
df2 <- df %>%
mutate(
hiv_diagnoses = ifelse(is.na(hiv_diagnoses), 0, hiv_diagnoses),
aids_diagnoses = ifelse(is.na(aids_diagnoses), 0, aids_diagnoses),
x_viral_suppression = ifelse(
is.na(x_viral_suppression),
median(x_viral_suppression, na.rm = TRUE),
x_viral_suppression
),
vs_class = ifelse(x_viral_suppression >= 0.85, "High", "Low"),
vs_class = as.factor(vs_class)
)
df_model <- df2 %>%
select(vs_class, year, borough, uhf, gender, age, race, hiv_diagnoses, aids_diagnoses) %>%
drop_na() %>%
mutate(across(c(year, borough, uhf, gender, age, race), as.factor))
set.seed(42)
split_idx <- createDataPartition(df_model$vs_class, p = 0.8, list = FALSE)
train2 <- df_model[split_idx, ]
test2  <- df_model[-split_idx, ]
# Train the Random Forest model
set.seed(42)
rf_model <- randomForest(
vs_class ~ .,
data = train2,
ntree = 100,
mtry = 3,
importance = TRUE
)
pred <- predict(rf_model, newdata = test2)
# confusion matrix
confusionMatrix(pred, test2$vs_class)
# visualize importance of variables
par(bg = "white")
varImpPlot(rf_model, main = "Variable Importance for x_viral_suppression Class")
# visualize the proportion of high viral suppression rates by UHF
df_model %>%
group_by(uhf) %>%
summarise(high_rate = mean(vs_class == "High")) %>%
ggplot(aes(x = reorder(uhf, high_rate), y = high_rate)) +
geom_col(fill = "#2C3E50") +
coord_flip() +
labs(title = "Proportion of 'High' Viral Suppression by UHF Region",
x = "UHF Region", y = "Proportion High") +
theme_minimal()
# visualize the proportion of high viral suppression rates by race
df_model %>%
group_by(race) %>%
summarise(high_rate = mean(vs_class == "High")) %>%
ggplot(aes(x = reorder(race, high_rate), y = high_rate)) +
geom_col(fill = "#2C3E50") +
coord_flip() +
labs(title = "Proportion of 'High' Viral Suppression by race",
x = "race", y = "Proportion High") +
theme_minimal()
pcadata <- read.csv("D:/APAN5205_Notes/Project/DOHMH_HIV_AIDS_Cleaned.csv")
pcadata <- pcadata %>%
mutate(
hiv_diagnoses = ifelse(is.na(hiv_diagnoses), 0, hiv_diagnoses),
hiv_diagnosis_rate = ifelse(is.na(hiv_diagnosis_rate), 0, hiv_diagnosis_rate),
concurrent_diagnoses = ifelse(is.na(concurrent_diagnoses), 0, concurrent_diagnoses),
x_linked_to_care_within_3_months = ifelse(
is.na(x_linked_to_care_within_3_months),
median(x_linked_to_care_within_3_months, na.rm = TRUE),
x_linked_to_care_within_3_months
),
aids_diagnoses = ifelse(is.na(aids_diagnoses), 0, aids_diagnoses),
aids_diagnosis_rate = ifelse(is.na(aids_diagnosis_rate), 0, aids_diagnosis_rate),
plwdhi_prevalence = ifelse(
is.na(plwdhi_prevalence),
median(plwdhi_prevalence, na.rm = TRUE),
plwdhi_prevalence
),
x_viral_suppression = ifelse(
is.na(x_viral_suppression),
median(x_viral_suppression, na.rm = TRUE),
x_viral_suppression
),
deaths = ifelse(is.na(deaths), 0, deaths),
death_rate = ifelse(is.na(death_rate), 0, death_rate),
hiv_related_death_rate = ifelse(is.na(hiv_related_death_rate), 0, hiv_related_death_rate)
)
library(caret)
set.seed(1706)
split = createDataPartition(y = pcadata$x_viral_suppression, p = 0.8, list = FALSE, groups = 100)
train3 = pcadata[split, ]
test3 = pcadata[-split, ]
# select the relevant variables for PCA-training and testing
train_pca <- train3 %>%
select(hiv_diagnoses, hiv_diagnosis_rate, concurrent_diagnoses,
aids_diagnoses, aids_diagnosis_rate, plwdhi_prevalence,
deaths, death_rate, hiv_related_death_rate, non_hiv_related_death_rate)
test_pca <- test3 %>%
select(hiv_diagnoses, hiv_diagnosis_rate, concurrent_diagnoses,
aids_diagnoses, aids_diagnosis_rate, plwdhi_prevalence,
deaths, death_rate, hiv_related_death_rate, non_hiv_related_death_rate)
# calculate correlation matrix
round(cor(train_pca, use = 'complete.obs'), 3)
# visualize the correlation matrix
library(tidyr)
library(dplyr)
library(ggplot2)
corMatrix <- cor(train_pca) %>%
as.data.frame()
corMatrix <- corMatrix %>%
mutate(var1 = rownames(.)) %>%
gather(key = "var2", value = "correlation", -var1)
ggplot(corMatrix, aes(x = var1, y = var2, fill = correlation)) +
geom_tile() +
geom_text(aes(label = round(correlation, 2)), size = 3) +
scale_fill_gradient2(
low = "red",
high = "green",
mid = "white",
midpoint = 0
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank()
) +
labs(title = "Heat map of correlation coefficients")
# scree plot
library(factoextra)
library(FactoMineR)
pca_facto = PCA(train_pca, graph = FALSE)
fviz_eig(pca_facto, ncp = 11, addlabels = TRUE, scale = TRUE)
# view eigenvalues
pca_facto$eig
# select eigenvalues greater than 1
pca_facto$eig[pca_facto$eig[,'eigenvalue'] > 1, ]
# each variable's contribution to the principal components
pca_facto$var$contrib %>% round(2)
# visualize the contribution of each variable to the principal components
library(factoextra)
library(gridExtra)
charts = lapply(1:3, FUN = function(x) {
fviz_contrib(pca_facto, choice = 'var', axes = x, title = paste('Dim', x))
})
grid.arrange(grobs = charts, ncol = 3, nrow = 1)
trainComponents = pca_facto$ind$coord
testComponents = predict(pca_facto, newdata = test_pca)$coord
trainComponents = cbind(trainComponents, x_viral_suppression = train3$x_viral_suppression)
testComponents = cbind(testComponents, x_viral_suppression = test3$x_viral_suppression)
trainComponents <- as.data.frame(trainComponents)
testComponents <- as.data.frame(testComponents)
head(trainComponents)
lm_model <- lm(x_viral_suppression ~ ., data = trainComponents)
summary(lm_model)
lm_model <- lm(x_viral_suppression ~ ., data = trainComponents)
summary(lm_model)
lm_model <- lm(x_viral_suppression ~ Dim.1 + Dim.2 + Dim.3, data = trainComponents)
summary(lm_model)
setwd(""C:\\Users\\Mark\\Desktop\\APAN5310 Group4"")
setwd(“C:\\Users\\Mark\\Desktop\\APAN5310 Group4")
setwd("C:\\Users\\Mark\\Desktop\\APAN5310 Group4")
library(shiny);runApp()
